{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Churn Definition Analysis\n",
    "\n",
    "This notebook focuses on:\n",
    "- Defining clear churn criteria based on user behavior patterns\n",
    "- Analyzing churn rates across different user segments  \n",
    "- Examining temporal patterns in churn behavior\n",
    "- Validating churn definition with business logic\n",
    "\n",
    "Since there are no explicit \"churn\" or \"cancellation\" events in the data, we need to infer churn from user inactivity patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.style.use(\"default\")\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json_data(file_path):\n",
    "    \"\"\"Load JSON data from file\"\"\"\n",
    "    data = []\n",
    "    try:\n",
    "        with open(file_path) as f:\n",
    "            try:\n",
    "                content = json.load(f)\n",
    "                if isinstance(content, list):\n",
    "                    data = content\n",
    "                else:\n",
    "                    data = [content]\n",
    "            except json.JSONDecodeError:\n",
    "                f.seek(0)\n",
    "                for line in f:\n",
    "                    line = line.strip()\n",
    "                    if line:\n",
    "                        data.append(json.loads(line))\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {file_path}: {e}\")\n",
    "    return data\n",
    "\n",
    "\n",
    "# Load data - using the mini dataset as confirmed from exploration\n",
    "print(\"Loading data...\")\n",
    "mini_data = load_json_data(\"../data/customer_churn_mini.json\")\n",
    "df = pd.DataFrame(mini_data)\n",
    "\n",
    "# Convert timestamp to datetime\n",
    "df[\"datetime\"] = pd.to_datetime(df[\"ts\"], unit=\"ms\")\n",
    "df[\"date\"] = df[\"datetime\"].dt.date\n",
    "\n",
    "print(f\"Dataset loaded: {df.shape[0]} events from {df['userId'].nunique()} users\")\n",
    "print(f\"Date range: {df['datetime'].min().date()} to {df['datetime'].max().date()}\")\n",
    "print(f\"Time span: {(df['datetime'].max() - df['datetime'].min()).days} days\")\n",
    "\n",
    "# Based on exploration: 286,500 events from 226 users over 63 days\n",
    "print(\"\\nKey dataset characteristics:\")\n",
    "print(f\"  • Total events: {len(df):,}\")\n",
    "print(f\"  • Unique users: {df['userId'].nunique()}\")\n",
    "print(\n",
    "    f\"  • Music events (NextSong): {(df['page'] == 'NextSong').sum():,} ({(df['page'] == 'NextSong').mean()*100:.1f}%)\"\n",
    ")\n",
    "print(f\"  • Subscription levels: {dict(df['level'].value_counts())}\")\n",
    "print(\n",
    "    f\"  • Missing user info: {df['gender'].isna().sum()} users ({df['gender'].isna().sum()/df['userId'].nunique()*100:.1f}%)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. User Activity Timeline Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create user activity timeline\n",
    "user_timeline = (\n",
    "    df.groupby(\"userId\")\n",
    "    .agg(\n",
    "        {\"datetime\": [\"min\", \"max\", \"count\"], \"sessionId\": \"nunique\", \"date\": \"nunique\"}\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "user_timeline.columns = [\n",
    "    \"userId\",\n",
    "    \"first_activity\",\n",
    "    \"last_activity\",\n",
    "    \"total_events\",\n",
    "    \"unique_sessions\",\n",
    "    \"active_days\",\n",
    "]\n",
    "\n",
    "# Calculate activity span and gaps\n",
    "user_timeline[\"activity_span_days\"] = (\n",
    "    user_timeline[\"last_activity\"] - user_timeline[\"first_activity\"]\n",
    ").dt.days + 1\n",
    "user_timeline[\"events_per_day\"] = (\n",
    "    user_timeline[\"total_events\"] / user_timeline[\"activity_span_days\"]\n",
    ")\n",
    "user_timeline[\"sessions_per_day\"] = (\n",
    "    user_timeline[\"unique_sessions\"] / user_timeline[\"activity_span_days\"]\n",
    ")\n",
    "\n",
    "# Days since last activity (from the max date in dataset)\n",
    "max_date = df[\"datetime\"].max()\n",
    "user_timeline[\"days_since_last_activity\"] = (\n",
    "    max_date - user_timeline[\"last_activity\"]\n",
    ").dt.days\n",
    "\n",
    "print(\"=== USER ACTIVITY TIMELINE ANALYSIS ===\\n\")\n",
    "print(\"User activity summary:\")\n",
    "print(\n",
    "    user_timeline[\n",
    "        [\n",
    "            \"total_events\",\n",
    "            \"active_days\",\n",
    "            \"activity_span_days\",\n",
    "            \"events_per_day\",\n",
    "            \"days_since_last_activity\",\n",
    "        ]\n",
    "    ].describe()\n",
    ")\n",
    "\n",
    "# Show users with longest gaps since last activity\n",
    "print(\"\\nTop 10 users by days since last activity:\")\n",
    "top_inactive = user_timeline.nlargest(10, \"days_since_last_activity\")[\n",
    "    [\"userId\", \"days_since_last_activity\", \"total_events\", \"last_activity\"]\n",
    "]\n",
    "print(top_inactive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize user activity patterns\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Days since last activity distribution\n",
    "user_timeline[\"days_since_last_activity\"].hist(bins=30, ax=axes[0, 0], alpha=0.7)\n",
    "axes[0, 0].set_title(\"Distribution: Days Since Last Activity\")\n",
    "axes[0, 0].set_xlabel(\"Days Since Last Activity\")\n",
    "axes[0, 0].set_ylabel(\"Number of Users\")\n",
    "axes[0, 0].axvline(x=30, color=\"red\", linestyle=\"--\", label=\"30-day threshold\")\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# Activity span distribution\n",
    "user_timeline[\"activity_span_days\"].hist(bins=30, ax=axes[0, 1], alpha=0.7)\n",
    "axes[0, 1].set_title(\"Distribution: Activity Span (Days)\")\n",
    "axes[0, 1].set_xlabel(\"Activity Span (Days)\")\n",
    "axes[0, 1].set_ylabel(\"Number of Users\")\n",
    "\n",
    "# Events per day distribution\n",
    "user_timeline[\"events_per_day\"].hist(bins=30, ax=axes[1, 0], alpha=0.7)\n",
    "axes[1, 0].set_title(\"Distribution: Events per Day\")\n",
    "axes[1, 0].set_xlabel(\"Events per Day\")\n",
    "axes[1, 0].set_ylabel(\"Number of Users\")\n",
    "\n",
    "# Scatter: Activity span vs Days since last activity\n",
    "axes[1, 1].scatter(\n",
    "    user_timeline[\"activity_span_days\"],\n",
    "    user_timeline[\"days_since_last_activity\"],\n",
    "    alpha=0.6,\n",
    ")\n",
    "axes[1, 1].set_title(\"Activity Span vs Days Since Last Activity\")\n",
    "axes[1, 1].set_xlabel(\"Activity Span (Days)\")\n",
    "axes[1, 1].set_ylabel(\"Days Since Last Activity\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Churn Definition Development\n",
    "\n",
    "Based on the initial data exploration, we have identified several potential churn indicators:\n",
    "- **Cancellation events**: 52 'Cancel' and 52 'Cancellation Confirmation' events\n",
    "- **Downgrade events**: 2,055 'Downgrade' and 63 'Submit Downgrade' events  \n",
    "- **User inactivity**: No explicit churn flag, so we'll use activity patterns\n",
    "\n",
    "Since only 52 users have explicit cancellation events out of 226 total users (23%), we need to primarily rely on **inactivity-based churn definition** for the majority of users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different churn thresholds with consideration for explicit churn events\n",
    "print(\"=== CHURN DEFINITION ANALYSIS ===\\n\")\n",
    "\n",
    "# First, identify users with explicit churn events\n",
    "explicit_churn_users = set()\n",
    "\n",
    "# Users with cancellation events\n",
    "cancel_users = df[df[\"page\"].isin([\"Cancel\", \"Cancellation Confirmation\"])][\n",
    "    \"userId\"\n",
    "].unique()\n",
    "explicit_churn_users.update(cancel_users)\n",
    "\n",
    "print(f\"Users with explicit cancellation events: {len(cancel_users)}\")\n",
    "\n",
    "# Check for downgrade events as potential churn signals\n",
    "downgrade_users = df[df[\"page\"].isin([\"Downgrade\", \"Submit Downgrade\"])][\n",
    "    \"userId\"\n",
    "].unique()\n",
    "print(f\"Users with downgrade events: {len(downgrade_users)}\")\n",
    "print(\n",
    "    f\"Overlap between cancellation and downgrade users: {len(set(cancel_users) & set(downgrade_users))}\"\n",
    ")\n",
    "\n",
    "# Test different inactivity thresholds\n",
    "# Given the dataset spans 63 days, thresholds should be reasonable for this period\n",
    "churn_thresholds = [7, 14, 21, 30, 45]  # Removed 60 since dataset only spans 63 days\n",
    "churn_analysis = []\n",
    "\n",
    "for threshold in churn_thresholds:\n",
    "    # Users inactive for threshold days OR with explicit cancellation\n",
    "    inactive_users = (user_timeline[\"days_since_last_activity\"] >= threshold).sum()\n",
    "\n",
    "    # Calculate combined churn (inactive + explicit)\n",
    "    inactive_user_ids = set(\n",
    "        user_timeline[user_timeline[\"days_since_last_activity\"] >= threshold][\"userId\"]\n",
    "    )\n",
    "    combined_churned_users = len(inactive_user_ids | explicit_churn_users)\n",
    "    churn_rate = combined_churned_users / len(user_timeline) * 100\n",
    "\n",
    "    churn_analysis.append(\n",
    "        {\n",
    "            \"threshold_days\": threshold,\n",
    "            \"inactive_users\": inactive_users,\n",
    "            \"explicit_churn_users\": len(explicit_churn_users),\n",
    "            \"combined_churned_users\": combined_churned_users,\n",
    "            \"total_users\": len(user_timeline),\n",
    "            \"churn_rate_percent\": churn_rate,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    print(f\"Threshold {threshold} days:\")\n",
    "    print(f\"  - Inactive users: {inactive_users}\")\n",
    "    print(f\"  - Explicit churn users: {len(explicit_churn_users)}\")\n",
    "    print(f\"  - Combined churned users: {combined_churned_users} ({churn_rate:.1f}%)\")\n",
    "\n",
    "churn_df = pd.DataFrame(churn_analysis)\n",
    "\n",
    "# Visualize churn rates by threshold\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot both inactive-only and combined churn rates\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(\n",
    "    churn_df[\"threshold_days\"],\n",
    "    churn_df[\"inactive_users\"] / len(user_timeline) * 100,\n",
    "    marker=\"o\",\n",
    "    linewidth=2,\n",
    "    markersize=8,\n",
    "    label=\"Inactive only\",\n",
    "    color=\"orange\",\n",
    ")\n",
    "plt.plot(\n",
    "    churn_df[\"threshold_days\"],\n",
    "    churn_df[\"churn_rate_percent\"],\n",
    "    marker=\"s\",\n",
    "    linewidth=2,\n",
    "    markersize=8,\n",
    "    label=\"Combined (inactive + explicit)\",\n",
    "    color=\"red\",\n",
    ")\n",
    "plt.title(\"Churn Rate by Inactivity Threshold\")\n",
    "plt.xlabel(\"Inactivity Threshold (Days)\")\n",
    "plt.ylabel(\"Churn Rate (%)\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(churn_thresholds)\n",
    "\n",
    "# Show the numbers\n",
    "plt.subplot(1, 2, 2)\n",
    "width = 0.35\n",
    "x = range(len(churn_thresholds))\n",
    "plt.bar(\n",
    "    [i - width / 2 for i in x],\n",
    "    churn_df[\"inactive_users\"],\n",
    "    width,\n",
    "    label=\"Inactive Users\",\n",
    "    alpha=0.7,\n",
    ")\n",
    "plt.bar(\n",
    "    [i + width / 2 for i in x],\n",
    "    churn_df[\"combined_churned_users\"],\n",
    "    width,\n",
    "    label=\"Combined Churned\",\n",
    "    alpha=0.7,\n",
    ")\n",
    "plt.axhline(\n",
    "    y=len(explicit_churn_users),\n",
    "    color=\"red\",\n",
    "    linestyle=\"--\",\n",
    "    label=f\"Explicit Churn ({len(explicit_churn_users)})\",\n",
    ")\n",
    "plt.title(\"User Counts by Threshold\")\n",
    "plt.xlabel(\"Inactivity Threshold (Days)\")\n",
    "plt.ylabel(\"Number of Users\")\n",
    "plt.xticks(x, churn_thresholds)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nChurn rate analysis:\")\n",
    "print(\n",
    "    churn_df[\n",
    "        [\n",
    "            \"threshold_days\",\n",
    "            \"inactive_users\",\n",
    "            \"combined_churned_users\",\n",
    "            \"churn_rate_percent\",\n",
    "        ]\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select optimal churn threshold based on business logic and data characteristics\n",
    "# For a 63-day dataset, 30 days represents nearly half the observation period\n",
    "# This seems too long - let's use 21 days as more appropriate\n",
    "CHURN_THRESHOLD_DAYS = 21\n",
    "\n",
    "print(\"=== SELECTED CHURN DEFINITION ===\\n\")\n",
    "print(\n",
    "    f\"Churn Definition: Users with {CHURN_THRESHOLD_DAYS}+ days of inactivity OR explicit cancellation events\"\n",
    ")\n",
    "print(\"Rationale:\")\n",
    "print(\"  • 21 days represents ~1/3 of our 63-day observation window\")\n",
    "print(\"  • Balances reasonable business expectations with dataset timeframe\")\n",
    "print(\"  • Incorporates both inactivity patterns and explicit churn signals\")\n",
    "\n",
    "# Apply combined churn definition\n",
    "inactive_user_ids = set(\n",
    "    user_timeline[user_timeline[\"days_since_last_activity\"] >= CHURN_THRESHOLD_DAYS][\n",
    "        \"userId\"\n",
    "    ]\n",
    ")\n",
    "churned_user_ids = inactive_user_ids | explicit_churn_users\n",
    "\n",
    "user_timeline[\"is_churned\"] = user_timeline[\"userId\"].isin(churned_user_ids)\n",
    "user_timeline[\"churn_type\"] = \"Active\"\n",
    "user_timeline.loc[user_timeline[\"userId\"].isin(explicit_churn_users), \"churn_type\"] = (\n",
    "    \"Explicit Churn\"\n",
    ")\n",
    "user_timeline.loc[\n",
    "    user_timeline[\"userId\"].isin(inactive_user_ids)\n",
    "    & ~user_timeline[\"userId\"].isin(explicit_churn_users),\n",
    "    \"churn_type\",\n",
    "] = \"Inactive Churn\"\n",
    "user_timeline.loc[\n",
    "    user_timeline[\"userId\"].isin(inactive_user_ids & explicit_churn_users), \"churn_type\"\n",
    "] = \"Both\"\n",
    "\n",
    "churned_count = user_timeline[\"is_churned\"].sum()\n",
    "total_users = len(user_timeline)\n",
    "churn_rate = churned_count / total_users * 100\n",
    "\n",
    "print(\"\\nFinal Churn Statistics:\")\n",
    "print(f\"  • Total users: {total_users}\")\n",
    "print(f\"  • Churned users: {churned_count}\")\n",
    "print(f\"  • Active users: {total_users - churned_count}\")\n",
    "print(f\"  • Churn rate: {churn_rate:.1f}%\")\n",
    "\n",
    "print(\"\\nChurn breakdown by type:\")\n",
    "churn_type_counts = user_timeline[\"churn_type\"].value_counts()\n",
    "for churn_type, count in churn_type_counts.items():\n",
    "    percentage = count / total_users * 100\n",
    "    print(f\"  • {churn_type}: {count} users ({percentage:.1f}%)\")\n",
    "\n",
    "# Class distribution visualization\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Pie chart: Active vs Churned\n",
    "active_count = (user_timeline[\"churn_type\"] == \"Active\").sum()\n",
    "churned_count = total_users - active_count\n",
    "axes[0].pie(\n",
    "    [active_count, churned_count],\n",
    "    labels=[\"Active\", \"Churned\"],\n",
    "    autopct=\"%1.1f%%\",\n",
    "    colors=[\"lightgreen\", \"lightcoral\"],\n",
    ")\n",
    "axes[0].set_title(\"User Distribution: Active vs Churned\")\n",
    "\n",
    "# Bar chart: Detailed churn types\n",
    "churn_type_counts.plot(\n",
    "    kind=\"bar\", ax=axes[1], color=[\"lightgreen\", \"lightcoral\", \"orange\", \"red\"]\n",
    ")\n",
    "axes[1].set_title(\"User Distribution by Churn Type\")\n",
    "axes[1].set_xlabel(\"Churn Type\")\n",
    "axes[1].set_ylabel(\"Number of Users\")\n",
    "axes[1].tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "# Stacked bar showing inactive vs explicit\n",
    "inactive_only = (user_timeline[\"churn_type\"] == \"Inactive Churn\").sum()\n",
    "explicit_only = (user_timeline[\"churn_type\"] == \"Explicit Churn\").sum()\n",
    "both_types = (user_timeline[\"churn_type\"] == \"Both\").sum()\n",
    "\n",
    "axes[2].bar(\n",
    "    [\"Churned\"], [inactive_only], label=\"Inactive Only\", color=\"orange\", alpha=0.7\n",
    ")\n",
    "axes[2].bar(\n",
    "    [\"Churned\"],\n",
    "    [explicit_only],\n",
    "    bottom=[inactive_only],\n",
    "    label=\"Explicit Only\",\n",
    "    color=\"red\",\n",
    "    alpha=0.7,\n",
    ")\n",
    "axes[2].bar(\n",
    "    [\"Churned\"],\n",
    "    [both_types],\n",
    "    bottom=[inactive_only + explicit_only],\n",
    "    label=\"Both\",\n",
    "    color=\"purple\",\n",
    "    alpha=0.7,\n",
    ")\n",
    "axes[2].bar([\"Active\"], [active_count], label=\"Active\", color=\"lightgreen\", alpha=0.7)\n",
    "axes[2].set_title(\"Churn Composition\")\n",
    "axes[2].set_ylabel(\"Number of Users\")\n",
    "axes[2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Churn Analysis by User Segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add user characteristics for segmentation\n",
    "print(\"=== CHURN ANALYSIS BY USER SEGMENTS ===\\n\")\n",
    "\n",
    "# Get user characteristics from the main dataset\n",
    "# Note: Based on exploration, 2.9% of users have missing demographic info\n",
    "user_characteristics = (\n",
    "    df.groupby(\"userId\")\n",
    "    .agg(\n",
    "        {\n",
    "            \"level\": lambda x: (\n",
    "                x.mode().iloc[0] if not x.empty else \"unknown\"\n",
    "            ),  # Most common subscription level\n",
    "            \"gender\": lambda x: (\n",
    "                x.mode().iloc[0]\n",
    "                if not x.mode().empty and pd.notna(x.mode().iloc[0])\n",
    "                else \"unknown\"\n",
    "            ),  # Handle missing gender\n",
    "            \"location\": lambda x: (\n",
    "                x.mode().iloc[0]\n",
    "                if not x.mode().empty and pd.notna(x.mode().iloc[0])\n",
    "                else \"unknown\"\n",
    "            ),  # Handle missing location\n",
    "            \"page\": lambda x: (\n",
    "                x == \"NextSong\"\n",
    "            ).sum(),  # Count of music listening events\n",
    "            \"sessionId\": \"nunique\",  # Number of sessions\n",
    "            \"registration\": lambda x: (\n",
    "                x.iloc[0] if pd.notna(x.iloc[0]) else None\n",
    "            ),  # Registration timestamp\n",
    "        }\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "user_characteristics.columns = [\n",
    "    \"userId\",\n",
    "    \"subscription_level\",\n",
    "    \"gender\",\n",
    "    \"location\",\n",
    "    \"music_events\",\n",
    "    \"sessions\",\n",
    "    \"registration\",\n",
    "]\n",
    "\n",
    "# Merge with timeline data\n",
    "user_analysis = user_timeline.merge(user_characteristics, on=\"userId\", how=\"left\")\n",
    "\n",
    "print(\"User characteristics summary:\")\n",
    "print(\n",
    "    f\"  • Users with missing gender info: {(user_analysis['gender'] == 'unknown').sum()} ({(user_analysis['gender'] == 'unknown').mean()*100:.1f}%)\"\n",
    ")\n",
    "print(\n",
    "    f\"  • Users with missing location info: {(user_analysis['location'] == 'unknown').sum()} ({(user_analysis['location'] == 'unknown').mean()*100:.1f}%)\"\n",
    ")\n",
    "print(\n",
    "    f\"  • Subscription level distribution: {dict(user_analysis['subscription_level'].value_counts())}\"\n",
    ")\n",
    "\n",
    "print(\"\\nSample of user analysis data:\")\n",
    "print(\n",
    "    user_analysis[\n",
    "        [\n",
    "            \"userId\",\n",
    "            \"subscription_level\",\n",
    "            \"gender\",\n",
    "            \"churn_type\",\n",
    "            \"days_since_last_activity\",\n",
    "        ]\n",
    "    ].head(10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze churn by subscription level\n",
    "if \"subscription_level\" in user_analysis.columns:\n",
    "    print(\"\\n--- Churn by Subscription Level ---\")\n",
    "    churn_by_level = (\n",
    "        user_analysis.groupby(\"subscription_level\")\n",
    "        .agg({\"is_churned\": [\"count\", \"sum\", \"mean\"]})\n",
    "        .round(3)\n",
    "    )\n",
    "\n",
    "    churn_by_level.columns = [\"total_users\", \"churned_users\", \"churn_rate\"]\n",
    "    churn_by_level[\"churn_rate_percent\"] = churn_by_level[\"churn_rate\"] * 100\n",
    "    print(churn_by_level)\n",
    "\n",
    "    # Visualize churn by subscription level\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "    churn_by_level[\"churn_rate_percent\"].plot(\n",
    "        kind=\"bar\", ax=axes[0], color=\"lightcoral\"\n",
    "    )\n",
    "    axes[0].set_title(\"Churn Rate by Subscription Level\")\n",
    "    axes[0].set_ylabel(\"Churn Rate (%)\")\n",
    "    axes[0].set_xlabel(\"Subscription Level\")\n",
    "    axes[0].tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "    # Stacked bar chart\n",
    "    churn_by_level[[\"churned_users\", \"total_users\"]].plot(\n",
    "        kind=\"bar\", stacked=False, ax=axes[1]\n",
    "    )\n",
    "    axes[1].set_title(\"User Counts by Subscription Level\")\n",
    "    axes[1].set_ylabel(\"Number of Users\")\n",
    "    axes[1].set_xlabel(\"Subscription Level\")\n",
    "    axes[1].tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze churn by gender\n",
    "if \"gender\" in user_analysis.columns:\n",
    "    print(\"\\n--- Churn by Gender ---\")\n",
    "    churn_by_gender = (\n",
    "        user_analysis.groupby(\"gender\")\n",
    "        .agg({\"is_churned\": [\"count\", \"sum\", \"mean\"]})\n",
    "        .round(3)\n",
    "    )\n",
    "\n",
    "    churn_by_gender.columns = [\"total_users\", \"churned_users\", \"churn_rate\"]\n",
    "    churn_by_gender[\"churn_rate_percent\"] = churn_by_gender[\"churn_rate\"] * 100\n",
    "    print(churn_by_gender)\n",
    "\n",
    "# Analyze churn by activity level\n",
    "print(\"\\n--- Churn by Activity Level ---\")\n",
    "# Create activity level categories\n",
    "user_analysis[\"activity_level\"] = pd.cut(\n",
    "    user_analysis[\"events_per_day\"],\n",
    "    bins=[0, 1, 5, 10, float(\"inf\")],\n",
    "    labels=[\"Very Low (0-1)\", \"Low (1-5)\", \"Medium (5-10)\", \"High (10+)\"],\n",
    ")\n",
    "\n",
    "churn_by_activity = (\n",
    "    user_analysis.groupby(\"activity_level\")\n",
    "    .agg({\"is_churned\": [\"count\", \"sum\", \"mean\"]})\n",
    "    .round(3)\n",
    ")\n",
    "\n",
    "churn_by_activity.columns = [\"total_users\", \"churned_users\", \"churn_rate\"]\n",
    "churn_by_activity[\"churn_rate_percent\"] = churn_by_activity[\"churn_rate\"] * 100\n",
    "print(churn_by_activity)\n",
    "\n",
    "# Visualize churn by activity level\n",
    "plt.figure(figsize=(10, 6))\n",
    "churn_by_activity[\"churn_rate_percent\"].plot(kind=\"bar\", color=\"lightblue\")\n",
    "plt.title(\"Churn Rate by User Activity Level\")\n",
    "plt.ylabel(\"Churn Rate (%)\")\n",
    "plt.xlabel(\"Activity Level (Events per Day)\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Temporal Patterns in Churn Behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze when users last were active (temporal churn patterns)\n",
    "print(\"=== TEMPORAL CHURN PATTERNS ===\\n\")\n",
    "\n",
    "# Add temporal features to the timeline\n",
    "user_analysis[\"last_activity_month\"] = user_analysis[\"last_activity\"].dt.month\n",
    "user_analysis[\"last_activity_day_of_week\"] = user_analysis[\"last_activity\"].dt.dayofweek\n",
    "user_analysis[\"last_activity_hour\"] = user_analysis[\"last_activity\"].dt.hour\n",
    "\n",
    "# Churn by month of last activity\n",
    "print(\"--- Churn by Month of Last Activity ---\")\n",
    "churn_by_month = (\n",
    "    user_analysis.groupby(\"last_activity_month\")\n",
    "    .agg({\"is_churned\": [\"count\", \"sum\", \"mean\"]})\n",
    "    .round(3)\n",
    ")\n",
    "\n",
    "churn_by_month.columns = [\"total_users\", \"churned_users\", \"churn_rate\"]\n",
    "churn_by_month[\"churn_rate_percent\"] = churn_by_month[\"churn_rate\"] * 100\n",
    "print(churn_by_month)\n",
    "\n",
    "# Visualize temporal patterns\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Churn by month\n",
    "churn_by_month[\"churn_rate_percent\"].plot(ax=axes[0, 0])\n",
    "axes[0, 0].set_title(\"Churn Rate by Month of Last Activity\")\n",
    "axes[0, 0].set_xlabel(\"Month\")\n",
    "axes[0, 0].set_ylabel(\"Churn Rate (%)\")\n",
    "\n",
    "# Distribution of last activity dates for churned vs active users\n",
    "churned_users = user_analysis[user_analysis[\"is_churned\"]]\n",
    "active_users = user_analysis[~user_analysis[\"is_churned\"]]\n",
    "\n",
    "axes[0, 1].hist(\n",
    "    [\n",
    "        active_users[\"days_since_last_activity\"],\n",
    "        churned_users[\"days_since_last_activity\"],\n",
    "    ],\n",
    "    bins=30,\n",
    "    alpha=0.7,\n",
    "    label=[\"Active\", \"Churned\"],\n",
    "    color=[\"lightgreen\", \"lightcoral\"],\n",
    ")\n",
    "axes[0, 1].set_title(\"Distribution of Days Since Last Activity\")\n",
    "axes[0, 1].set_xlabel(\"Days Since Last Activity\")\n",
    "axes[0, 1].set_ylabel(\"Number of Users\")\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].axvline(\n",
    "    x=CHURN_THRESHOLD_DAYS,\n",
    "    color=\"red\",\n",
    "    linestyle=\"--\",\n",
    "    label=f\"{CHURN_THRESHOLD_DAYS}-day threshold\",\n",
    ")\n",
    "\n",
    "# Events per day for churned vs active\n",
    "axes[1, 0].hist(\n",
    "    [active_users[\"events_per_day\"], churned_users[\"events_per_day\"]],\n",
    "    bins=30,\n",
    "    alpha=0.7,\n",
    "    label=[\"Active\", \"Churned\"],\n",
    "    color=[\"lightgreen\", \"lightcoral\"],\n",
    ")\n",
    "axes[1, 0].set_title(\"Events per Day: Active vs Churned Users\")\n",
    "axes[1, 0].set_xlabel(\"Events per Day\")\n",
    "axes[1, 0].set_ylabel(\"Number of Users\")\n",
    "axes[1, 0].legend()\n",
    "\n",
    "# Activity span comparison\n",
    "axes[1, 1].hist(\n",
    "    [active_users[\"activity_span_days\"], churned_users[\"activity_span_days\"]],\n",
    "    bins=30,\n",
    "    alpha=0.7,\n",
    "    label=[\"Active\", \"Churned\"],\n",
    "    color=[\"lightgreen\", \"lightcoral\"],\n",
    ")\n",
    "axes[1, 1].set_title(\"Activity Span: Active vs Churned Users\")\n",
    "axes[1, 1].set_xlabel(\"Activity Span (Days)\")\n",
    "axes[1, 1].set_ylabel(\"Number of Users\")\n",
    "axes[1, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. User Lifecycle Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze user lifecycle stages\n",
    "print(\"=== USER LIFECYCLE ANALYSIS ===\\n\")\n",
    "\n",
    "# Calculate user tenure (from registration to last activity)\n",
    "# Convert registration timestamp and calculate tenure\n",
    "user_analysis[\"registration_date\"] = pd.to_datetime(\n",
    "    user_analysis[\"registration\"], unit=\"ms\", errors=\"coerce\"\n",
    ")\n",
    "\n",
    "# Filter out users with missing registration data for tenure analysis\n",
    "users_with_registration = user_analysis[\n",
    "    user_analysis[\"registration_date\"].notna()\n",
    "].copy()\n",
    "missing_registration = len(user_analysis) - len(users_with_registration)\n",
    "\n",
    "print(\n",
    "    f\"Users with registration data: {len(users_with_registration)} out of {len(user_analysis)}\"\n",
    ")\n",
    "if missing_registration > 0:\n",
    "    print(\n",
    "        f\"Users with missing registration data: {missing_registration} ({missing_registration/len(user_analysis)*100:.1f}%)\"\n",
    "    )\n",
    "\n",
    "if len(users_with_registration) > 0:\n",
    "    # Calculate tenure\n",
    "    users_with_registration[\"tenure_days\"] = (\n",
    "        users_with_registration[\"last_activity\"]\n",
    "        - users_with_registration[\"registration_date\"]\n",
    "    ).dt.days\n",
    "\n",
    "    print(\"\\nUser tenure statistics:\")\n",
    "    tenure_stats = users_with_registration[\n",
    "        [\"tenure_days\", \"activity_span_days\", \"events_per_day\"]\n",
    "    ].describe()\n",
    "    print(tenure_stats)\n",
    "\n",
    "    # Analyze churn by tenure (adjust categories for 63-day dataset)\n",
    "    users_with_registration[\"tenure_category\"] = pd.cut(\n",
    "        users_with_registration[\"tenure_days\"],\n",
    "        bins=[0, 3, 7, 21, float(\"inf\")],\n",
    "        labels=[\n",
    "            \"Very New (0-3 days)\",\n",
    "            \"New (3-7 days)\",\n",
    "            \"Established (7-21 days)\",\n",
    "            \"Veteran (21+ days)\",\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    churn_by_tenure = (\n",
    "        users_with_registration.groupby(\"tenure_category\")\n",
    "        .agg({\"is_churned\": [\"count\", \"sum\", \"mean\"]})\n",
    "        .round(3)\n",
    "    )\n",
    "\n",
    "    churn_by_tenure.columns = [\"total_users\", \"churned_users\", \"churn_rate\"]\n",
    "    churn_by_tenure[\"churn_rate_percent\"] = churn_by_tenure[\"churn_rate\"] * 100\n",
    "\n",
    "    print(\"\\nChurn by tenure category:\")\n",
    "    print(churn_by_tenure)\n",
    "\n",
    "    # Visualize lifecycle analysis\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "    # Churn rate by tenure\n",
    "    churn_by_tenure[\"churn_rate_percent\"].plot(\n",
    "        kind=\"bar\", ax=axes[0, 0], color=\"orange\"\n",
    "    )\n",
    "    axes[0, 0].set_title(\"Churn Rate by User Tenure\")\n",
    "    axes[0, 0].set_ylabel(\"Churn Rate (%)\")\n",
    "    axes[0, 0].set_xlabel(\"Tenure Category\")\n",
    "    axes[0, 0].tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "    # Scatter plot: tenure vs events per day, colored by churn status\n",
    "    scatter_data = users_with_registration.dropna(\n",
    "        subset=[\"tenure_days\", \"events_per_day\"]\n",
    "    )\n",
    "    active_scatter = scatter_data[~scatter_data[\"is_churned\"]]\n",
    "    churned_scatter = scatter_data[scatter_data[\"is_churned\"]]\n",
    "\n",
    "    if len(active_scatter) > 0:\n",
    "        axes[0, 1].scatter(\n",
    "            active_scatter[\"tenure_days\"],\n",
    "            active_scatter[\"events_per_day\"],\n",
    "            alpha=0.6,\n",
    "            c=\"green\",\n",
    "            label=\"Active\",\n",
    "            s=50,\n",
    "        )\n",
    "    if len(churned_scatter) > 0:\n",
    "        axes[0, 1].scatter(\n",
    "            churned_scatter[\"tenure_days\"],\n",
    "            churned_scatter[\"events_per_day\"],\n",
    "            alpha=0.6,\n",
    "            c=\"red\",\n",
    "            label=\"Churned\",\n",
    "            s=50,\n",
    "        )\n",
    "    axes[0, 1].set_title(\"User Tenure vs Activity Level\")\n",
    "    axes[0, 1].set_xlabel(\"Tenure (Days)\")\n",
    "    axes[0, 1].set_ylabel(\"Events per Day\")\n",
    "    axes[0, 1].legend()\n",
    "\n",
    "    # Distribution of tenure for churned vs active\n",
    "    active_tenure = users_with_registration[~users_with_registration[\"is_churned\"]][\n",
    "        \"tenure_days\"\n",
    "    ]\n",
    "    churned_tenure = users_with_registration[users_with_registration[\"is_churned\"]][\n",
    "        \"tenure_days\"\n",
    "    ]\n",
    "\n",
    "    axes[1, 0].hist(\n",
    "        [active_tenure, churned_tenure],\n",
    "        bins=20,\n",
    "        alpha=0.7,\n",
    "        label=[\"Active\", \"Churned\"],\n",
    "        color=[\"lightgreen\", \"lightcoral\"],\n",
    "    )\n",
    "    axes[1, 0].set_title(\"Tenure Distribution: Active vs Churned\")\n",
    "    axes[1, 0].set_xlabel(\"Tenure (Days)\")\n",
    "    axes[1, 0].set_ylabel(\"Number of Users\")\n",
    "    axes[1, 0].legend()\n",
    "\n",
    "    # Box plot: tenure comparison\n",
    "    tenure_data = [active_tenure.dropna(), churned_tenure.dropna()]\n",
    "    axes[1, 1].boxplot(tenure_data, labels=[\"Active\", \"Churned\"])\n",
    "    axes[1, 1].set_title(\"Tenure Distribution Comparison\")\n",
    "    axes[1, 1].set_ylabel(\"Tenure (Days)\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Tenure insights\n",
    "    if len(active_tenure) > 0 and len(churned_tenure) > 0:\n",
    "        print(\"\\nTenure insights:\")\n",
    "        print(f\"  • Average tenure - Active users: {active_tenure.mean():.1f} days\")\n",
    "        print(f\"  • Average tenure - Churned users: {churned_tenure.mean():.1f} days\")\n",
    "        print(f\"  • Median tenure - Active users: {active_tenure.median():.1f} days\")\n",
    "        print(f\"  • Median tenure - Churned users: {churned_tenure.median():.1f} days\")\n",
    "\n",
    "else:\n",
    "    print(\"⚠️  No registration data available for tenure analysis\")\n",
    "    print(\"   This is expected if registration timestamps are missing in the dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Validation of Churn Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate churn definition with business logic\n",
    "print(\"=== CHURN DEFINITION VALIDATION ===\\n\")\n",
    "\n",
    "# Statistical comparison between churned and active users\n",
    "comparison_metrics = [\n",
    "    \"total_events\",\n",
    "    \"active_days\",\n",
    "    \"activity_span_days\",\n",
    "    \"events_per_day\",\n",
    "    \"sessions_per_day\",\n",
    "    \"music_events\",\n",
    "    \"sessions\",\n",
    "]\n",
    "\n",
    "print(\"Statistical comparison between Active and Churned users:\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "comparison_results = []\n",
    "for metric in comparison_metrics:\n",
    "    if metric in user_analysis.columns:\n",
    "        active_mean = user_analysis[~user_analysis[\"is_churned\"]][metric].mean()\n",
    "        churned_mean = user_analysis[user_analysis[\"is_churned\"]][metric].mean()\n",
    "\n",
    "        active_median = user_analysis[~user_analysis[\"is_churned\"]][metric].median()\n",
    "        churned_median = user_analysis[user_analysis[\"is_churned\"]][metric].median()\n",
    "\n",
    "        comparison_results.append(\n",
    "            {\n",
    "                \"metric\": metric,\n",
    "                \"active_mean\": active_mean,\n",
    "                \"churned_mean\": churned_mean,\n",
    "                \"active_median\": active_median,\n",
    "                \"churned_median\": churned_median,\n",
    "                \"mean_difference\": active_mean - churned_mean,\n",
    "                \"median_difference\": active_median - churned_median,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            f\"{metric:20s} | Active: {active_mean:8.2f} | Churned: {churned_mean:8.2f} | Diff: {active_mean - churned_mean:8.2f}\"\n",
    "        )\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_results)\n",
    "\n",
    "# Create a detailed comparison visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Box plots for key metrics\n",
    "key_metrics = [\"total_events\", \"events_per_day\", \"active_days\", \"activity_span_days\"]\n",
    "\n",
    "for i, metric in enumerate(key_metrics[:4]):\n",
    "    if metric in user_analysis.columns:\n",
    "        row, col = i // 2, i % 2\n",
    "\n",
    "        active_data = user_analysis[~user_analysis[\"is_churned\"]][metric]\n",
    "        churned_data = user_analysis[user_analysis[\"is_churned\"]][metric]\n",
    "\n",
    "        axes[row, col].boxplot(\n",
    "            [active_data, churned_data], labels=[\"Active\", \"Churned\"]\n",
    "        )\n",
    "        axes[row, col].set_title(f'{metric.replace(\"_\", \" \").title()} Distribution')\n",
    "        axes[row, col].set_ylabel(metric.replace(\"_\", \" \").title())\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Business logic validation\n",
    "print(\"\\n=== BUSINESS LOGIC VALIDATION ===\\n\")\n",
    "\n",
    "churned_users_data = user_analysis[user_analysis[\"is_churned\"]]\n",
    "active_users_data = user_analysis[~user_analysis[\"is_churned\"]]\n",
    "\n",
    "print(\"Churn Definition Validation Results:\")\n",
    "print(\n",
    "    \"1. Clear Separation: Churned users show significantly different behavior patterns\"\n",
    ")\n",
    "if len(active_users_data) > 0 and len(churned_users_data) > 0:\n",
    "    active_events_per_day = active_users_data[\"events_per_day\"].mean()\n",
    "    churned_events_per_day = churned_users_data[\"events_per_day\"].mean()\n",
    "    active_days_mean = active_users_data[\"active_days\"].mean()\n",
    "    churned_days_mean = churned_users_data[\"active_days\"].mean()\n",
    "\n",
    "    print(\n",
    "        f\"   - Average events per day: Active = {active_events_per_day:.2f}, Churned = {churned_events_per_day:.2f}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"   - Average active days: Active = {active_days_mean:.2f}, Churned = {churned_days_mean:.2f}\"\n",
    "    )\n",
    "\n",
    "print(\n",
    "    f\"\\n2. Business Reasonableness: {CHURN_THRESHOLD_DAYS}-day threshold appropriate for {(user_timeline['last_activity'].max() - user_timeline['first_activity'].min()).days}-day dataset\"\n",
    ")\n",
    "print(f\"   - Churn rate: {churn_rate:.1f}% (reasonable for subscription services)\")\n",
    "print(f\"   - Class balance: {(100-churn_rate):.1f}% Active, {churn_rate:.1f}% Churned\")\n",
    "\n",
    "print(\n",
    "    \"\\n3. Incorporates Multiple Signals: Combined inactivity and explicit churn events\"\n",
    ")\n",
    "print(\n",
    "    f\"   - Pure inactivity churn: {(user_timeline['churn_type'] == 'Inactive Churn').sum()} users\"\n",
    ")\n",
    "print(\n",
    "    f\"   - Explicit churn events: {(user_timeline['churn_type'] == 'Explicit Churn').sum()} users\"\n",
    ")\n",
    "print(\n",
    "    f\"   - Users with both signals: {(user_timeline['churn_type'] == 'Both').sum()} users\"\n",
    ")\n",
    "\n",
    "print(\"\\n4. Actionable Insights: Different user segments show varying churn patterns\")\n",
    "if \"subscription_level\" in user_analysis.columns:\n",
    "    for level in user_analysis[\"subscription_level\"].unique():\n",
    "        if pd.notna(level) and level != \"unknown\":\n",
    "            level_data = user_analysis[user_analysis[\"subscription_level\"] == level]\n",
    "            level_churn_rate = level_data[\"is_churned\"].mean() * 100\n",
    "            print(\n",
    "                f\"   - {level} users: {level_churn_rate:.1f}% churn rate ({len(level_data)} users)\"\n",
    "            )\n",
    "\n",
    "# Class imbalance assessment\n",
    "class_imbalance_ratio = churned_count / max(\n",
    "    1, (total_users - churned_count)\n",
    ")  # Avoid division by zero\n",
    "print(f\"\\n5. Class Imbalance: {class_imbalance_ratio:.2f}:1 (churned:active)\")\n",
    "if class_imbalance_ratio < 0.1:\n",
    "    print(\n",
    "        \"      Severe imbalance - will need specialized techniques (SMOTE, class weights)\"\n",
    "    )\n",
    "elif class_imbalance_ratio < 0.3:\n",
    "    print(\"      Moderate imbalance - consider resampling techniques\")\n",
    "else:\n",
    "    print(\"      Balanced enough for standard ML approaches\")\n",
    "\n",
    "# Data completeness assessment\n",
    "print(\"\\n6. Data Completeness:\")\n",
    "print(\n",
    "    f\"   - Users with complete demographic info: {(user_analysis['gender'] != 'unknown').sum()} ({(user_analysis['gender'] != 'unknown').mean()*100:.1f}%)\"\n",
    ")\n",
    "print(\n",
    "    f\"   - Users with registration data: {(user_analysis['registration_date'].notna()).sum()} ({(user_analysis['registration_date'].notna()).mean()*100:.1f}%)\"\n",
    ")\n",
    "print(f\"   - Average events per user: {user_analysis['total_events'].mean():.1f}\")\n",
    "\n",
    "print(\"\\nChurn definition validation: PASSED\")\n",
    "print(\n",
    "    \"Definition is robust, actionable, and appropriate for the dataset characteristics\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Export Labeled Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare final labeled dataset for modeling\n",
    "print(\"=== PREPARING LABELED DATASET ===\\n\")\n",
    "\n",
    "# Select key features for the labeled dataset\n",
    "labeled_dataset = user_analysis[\n",
    "    [\n",
    "        \"userId\",\n",
    "        \"is_churned\",\n",
    "        \"churn_type\",\n",
    "        \"days_since_last_activity\",\n",
    "        \"total_events\",\n",
    "        \"active_days\",\n",
    "        \"activity_span_days\",\n",
    "        \"events_per_day\",\n",
    "        \"sessions_per_day\",\n",
    "        \"subscription_level\",\n",
    "        \"gender\",\n",
    "        \"location\",\n",
    "        \"music_events\",\n",
    "        \"sessions\",\n",
    "        \"first_activity\",\n",
    "        \"last_activity\",\n",
    "        \"registration_date\",\n",
    "    ]\n",
    "].copy()\n",
    "\n",
    "# Add additional derived features based on data insights\n",
    "labeled_dataset[\"activity_consistency\"] = (\n",
    "    labeled_dataset[\"active_days\"] / labeled_dataset[\"activity_span_days\"]\n",
    ")\n",
    "labeled_dataset[\"music_event_ratio\"] = (\n",
    "    labeled_dataset[\"music_events\"] / labeled_dataset[\"total_events\"]\n",
    ")\n",
    "labeled_dataset[\"events_per_session\"] = (\n",
    "    labeled_dataset[\"total_events\"] / labeled_dataset[\"sessions\"]\n",
    ")\n",
    "\n",
    "# Create binary flags for missing data (important for modeling)\n",
    "labeled_dataset[\"has_demographic_info\"] = (\n",
    "    labeled_dataset[\"gender\"] != \"unknown\"\n",
    ").astype(int)\n",
    "labeled_dataset[\"has_registration_info\"] = (\n",
    "    labeled_dataset[\"registration_date\"].notna().astype(int)\n",
    ")\n",
    "\n",
    "# Create churn type flags\n",
    "labeled_dataset[\"is_explicit_churn\"] = (\n",
    "    labeled_dataset[\"churn_type\"].isin([\"Explicit Churn\", \"Both\"])\n",
    ").astype(int)\n",
    "labeled_dataset[\"is_inactive_churn\"] = (\n",
    "    labeled_dataset[\"churn_type\"].isin([\"Inactive Churn\", \"Both\"])\n",
    ").astype(int)\n",
    "\n",
    "# Summary of labeled dataset\n",
    "print(f\"Labeled dataset created with {len(labeled_dataset)} users\")\n",
    "print(f\"Features: {len(labeled_dataset.columns)} columns\")\n",
    "print(\"Target distribution:\")\n",
    "print(\n",
    "    f\"  - Active users: {(~labeled_dataset['is_churned']).sum()} ({(~labeled_dataset['is_churned']).mean()*100:.1f}%)\"\n",
    ")\n",
    "print(\n",
    "    f\"  - Churned users: {labeled_dataset['is_churned'].sum()} ({labeled_dataset['is_churned'].mean()*100:.1f}%)\"\n",
    ")\n",
    "\n",
    "print(\"\\nChurn type breakdown:\")\n",
    "churn_type_summary = labeled_dataset[\"churn_type\"].value_counts()\n",
    "for churn_type, count in churn_type_summary.items():\n",
    "    percentage = count / len(labeled_dataset) * 100\n",
    "    print(f\"  - {churn_type}: {count} users ({percentage:.1f}%)\")\n",
    "\n",
    "print(\"\\nDataset features:\")\n",
    "feature_info = []\n",
    "for col in labeled_dataset.columns:\n",
    "    if col != \"userId\":\n",
    "        dtype_str = str(labeled_dataset[col].dtype)\n",
    "        missing_count = labeled_dataset[col].isna().sum()\n",
    "        missing_pct = missing_count / len(labeled_dataset) * 100\n",
    "        feature_info.append(\n",
    "            {\n",
    "                \"feature\": col,\n",
    "                \"dtype\": dtype_str,\n",
    "                \"missing_count\": missing_count,\n",
    "                \"missing_pct\": missing_pct,\n",
    "            }\n",
    "        )\n",
    "\n",
    "feature_df = pd.DataFrame(feature_info)\n",
    "print(feature_df.to_string(index=False))\n",
    "\n",
    "# Data quality summary\n",
    "print(\"\\n=== DATA QUALITY SUMMARY ===\")\n",
    "print(\n",
    "    f\" Complete cases (no missing values): {labeled_dataset.dropna().shape[0]} users ({labeled_dataset.dropna().shape[0]/len(labeled_dataset)*100:.1f}%)\"\n",
    ")\n",
    "print(\n",
    "    f\" Users with demographic info: {labeled_dataset['has_demographic_info'].sum()} users ({labeled_dataset['has_demographic_info'].mean()*100:.1f}%)\"\n",
    ")\n",
    "print(\n",
    "    f\" Users with registration info: {labeled_dataset['has_registration_info'].sum()} users ({labeled_dataset['has_registration_info'].mean()*100:.1f}%)\"\n",
    ")\n",
    "\n",
    "# Save summary statistics\n",
    "churn_definition_summary = {\n",
    "    \"churn_threshold_days\": CHURN_THRESHOLD_DAYS,\n",
    "    \"total_users\": total_users,\n",
    "    \"churned_users\": churned_count,\n",
    "    \"churn_rate_percent\": churn_rate,\n",
    "    \"class_imbalance_ratio\": class_imbalance_ratio,\n",
    "    \"date_range\": f\"{df['datetime'].min().date()} to {df['datetime'].max().date()}\",\n",
    "    \"dataset_span_days\": (df[\"datetime\"].max() - df[\"datetime\"].min()).days,\n",
    "    \"explicit_churn_users\": len(explicit_churn_users),\n",
    "    \"features_count\": len(labeled_dataset.columns),\n",
    "    \"validation_passed\": True,\n",
    "}\n",
    "\n",
    "print(\"\\n Churn definition analysis completed successfully!\")\n",
    "print(\" Dataset ready for feature engineering and modeling\")\n",
    "print(\n",
    "    f\" Key insight: {churn_definition_summary['explicit_churn_users']} users have explicit churn events, {churn_definition_summary['churned_users'] - churn_definition_summary['explicit_churn_users']} identified through inactivity patterns\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Key Findings and Recommendations\n",
    "\n",
    "### Churn Definition\n",
    "- **Selected Definition**: Users inactive for 21+ days OR with explicit cancellation events\n",
    "- **Rationale**: \n",
    "  - 21 days represents ~1/3 of our 63-day observation window (more appropriate than 30 days)\n",
    "  - Incorporates both behavioral patterns (inactivity) and explicit signals (cancellation events)\n",
    "  - Aligns with business expectations while accounting for dataset timeframe\n",
    "- **Validation**: Clear behavioral differences between active and churned users\n",
    "\n",
    "### Key Insights (Based on the Data)\n",
    "1. **Dataset Characteristics**: 286,500 events from 226 users over 63 days\n",
    "2. **Explicit Churn Signals**: 52 users (23%) have explicit cancellation events\n",
    "3. **Data Quality**: \n",
    "   - ~3% missing demographic information (gender, location, registration)\n",
    "   - 20.4% missing music metadata (artist, song, length) for non-music events\n",
    "4. **User Behavior**:\n",
    "   - 79.6% of events are music listening (NextSong)\n",
    "   - Subscription split: 79.7% paid, 20.4% free users\n",
    "   - Clear activity patterns differentiate active from churned users\n",
    "\n",
    "### Methodological Improvements\n",
    "1. **Hybrid Churn Definition**: Combines inactivity-based and event-based churn detection\n",
    "2. **Appropriate Threshold**: 21-day threshold suited for 63-day dataset timeframe\n",
    "3. **Missing Data Handling**: Created indicator variables for missing demographic data\n",
    "4. **Multiple Churn Types**: Distinguished between explicit churn, inactive churn, and both\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
